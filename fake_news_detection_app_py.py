# -*- coding: utf-8 -*-
"""fake_news detection_app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UpUP8Y7_eQk5b7HNuaxw_meTFny5y79J
"""

!pip install streamlit

#import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

import streamlit as st
import pickle
import joblib

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

true_news = pd.read_csv('/content/drive/MyDrive/True.csv', encoding = 'latin-1', on_bad_lines = 'skip')
fake_news = pd.read_csv('/content/drive/MyDrive/Fake.csv', encoding ='latin-1', on_bad_lines ='skip')

true_news["class"] = 1
fake_news["class"] = 0

fake_news_manual_testing = fake_news.tail(10)
fake_news = fake_news.drop(fake_news.tail(10).index, inplace=False)


true_news_manual_testing = true_news.tail(10)
true_news = true_news.drop(true_news.tail(10).index, inplace=False)

true_news_manual_testing['class'] = 1
fake_news_manual_testing['class'] = 0

data_merge = pd.concat([true_news, fake_news], axis=0)

data = data_merge.drop(['title', 'subject', 'date'], axis=1)
data.head()

data = data.sample(frac=1)
data.head()

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

nltk.download('stopwords')
nltk.download('wordnet')

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)  # Remove special characters
    text = text.split()
    text = [word for word in text if word not in stop_words]  # Remove stopwords
    text = [lemmatizer.lemmatize(word) for word in text]  # Lemmatization
    return ' '.join(text)

data['cleaned_text'] = data['text'].apply(preprocess_text)

# Train-Test split
X = data['cleaned_text']
y = data['class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorization
vectorizer = TfidfVectorizer()
X_train_vector = vectorizer.fit_transform(X_train)
X_test_vector = vectorizer.transform(X_test)

from sklearn.model_selection import GridSearchCV

# Logistic Regression tuning
param_grid_lr = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}
grid_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5, scoring='accuracy')
grid_lr.fit(X_train_vector, y_train)

pred_lr = grid_lr.predict(X_test_vector)

grid_lr.score(X_test_vector, y_test)

print(classification_report(y_test, pred_lr))

best_lr = grid_lr.best_estimator_

for model, name in [(best_lr, 'Logistic Regression')]:
    predictions = model.predict(X_test_vector)
    print(f"Model: {name}")
    print(f"Accuracy: {accuracy_score(y_test, predictions)}")
    print(f"Classification Report:\n{classification_report(y_test, predictions)}")
    sns.heatmap(confusion_matrix(y_test, predictions), annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix for Logistic Regression model')
    plt.show()

filename = 'trained_model.sav'
pickle.dump(grid_lr, open(filename, 'wb'))

pickle.dump(vectorizer, open('vectorizer.pkl', 'wb'))

model = pickle.load(open('trained_model.sav', 'rb'))
vectorizer = pickle.load(open('vectorizer.pkl', 'rb'))

st.title('Fake News Detection')
st.write("Enter the news article text below to classify whether it is 'Real' or 'Fake'.")

news_text = st.text_area("News Article Text", height=300)

if st.button("Classify"):
    if news_text:  # If there's text input
        # Transform the input text using the vectorizer
        transformed_text = vectorizer.transform([news_text])

        # Make a prediction using the loaded model
        prediction = model.predict(transformed_text)
        result = 'Fake' if prediction[0] == 0 else 'Real'

        # Display the result
        st.success(f'The news is **{result}**.')
    else:
        st.error("Please enter some text to classify.")

# Sidebar inputs
st.sidebar.title("Fake News Detector")
st.sidebar.write("Enter the news article text below:")

news_text = st.sidebar.text_area("News Article Text", height=300)

if st.sidebar.button("Classify"):
    if news_text:
        transformed_text = vectorizer.transform([news_text])
        prediction = model.predict(transformed_text)
        result = 'Fake' if prediction[0] == 0 else 'Real'
        st.sidebar.success(f'The news is **{result}**.')
    else:
        st.sidebar.error("Please enter some text to classify.")

pip freeze > requirements.txt